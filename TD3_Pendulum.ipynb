{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQOxckwGt-4b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import gym\n",
        "from keras import layers, optimizers, losses\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class experience_memory():\n",
        "\n",
        "    def __init__(self, buffer_capacity, batch_size, state_dim, action_dim):\n",
        "        # Number of \"experiences\" to store at max\n",
        "        self.buffer_capacity = buffer_capacity\n",
        "        # Num of tuples to train on.\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Its tells us num of times record() was called.\n",
        "        self.buffer_counter = 0\n",
        "\n",
        "        # Instead of list of tuples as the exp.replay concept go\n",
        "        # We use different np.arrays for each tuple element\n",
        "        self.state_buffer = np.zeros((self.buffer_capacity, state_dim), dtype=np.float32)\n",
        "        self.action_buffer = np.zeros((self.buffer_capacity, action_dim), dtype=np.float32)\n",
        "        self.reward_buffer = np.zeros((self.buffer_capacity, 1), dtype=np.float32)\n",
        "        self.next_state_buffer = np.zeros((self.buffer_capacity, state_dim), dtype=np.float32)\n",
        "        self.done_buffer = np.zeros((self.buffer_capacity, 1), dtype=np.float32)\n",
        "\n",
        "    # Takes (s,a,r,s') obervation tuple as input\n",
        "    def record(self, obs_tuple):\n",
        "        # Set index to zero if buffer_capacity is exceeded,\n",
        "        # replacing old records\n",
        "        index = self.buffer_counter % self.buffer_capacity\n",
        "\n",
        "        self.state_buffer[index] = obs_tuple[0]\n",
        "        self.action_buffer[index] = obs_tuple[1]\n",
        "        self.reward_buffer[index] = obs_tuple[2]\n",
        "        self.next_state_buffer[index] = obs_tuple[3]\n",
        "        self.done_buffer[index] = obs_tuple[4]\n",
        "\n",
        "        self.buffer_counter += 1\n",
        "\n",
        "class Pendulum():\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.env = gym.make(\"Pendulum-v1\")\n",
        "        self.batch_size = 32\n",
        "        self.max_memory_size = 1000000\n",
        "\n",
        "        self.state_dim = 3\n",
        "        self.action_dim = 1\n",
        "\n",
        "        self.gamma = 1\n",
        "        self.tau = 0.005\n",
        "        self.lower_action_bound = -2\n",
        "        self.upper_action_bound = 2\n",
        "\n",
        "        self.buffer = experience_memory(self.max_memory_size, self.batch_size, self.state_dim, self.action_dim)\n",
        "\n",
        "        \n",
        "        # init the neural nets\n",
        "        self.critic = self.get_critic_NN()\n",
        "        self.target_critic = self.get_critic_NN()\n",
        "        self.target_critic.set_weights(self.critic.get_weights())\n",
        "     \n",
        "        self.actor = self.get_actor_NN()\n",
        "        self.target_actor = self.get_actor_NN()\n",
        "        self.target_actor.set_weights(self.actor.get_weights())\n",
        "\n",
        "\n",
        "        self.critic_lr = 0.0002\n",
        "        self.critic_optimizer = tf.keras.optimizers.Adam(self.critic_lr)\n",
        "        \n",
        "        self.actor_lr = 0.0001\n",
        "        self.actor_optimizer = tf.keras.optimizers.Adam(self.actor_lr)\n",
        "      \n",
        "        self.var = 0.1\n",
        "        self.var_decay = 1\n",
        "        self.lr_decay = 1\n",
        "\n",
        "       \n",
        "    def update_lr(self):\n",
        "        self.critic_lr = self.critic_lr * self.lr_decay\n",
        "        self.critic_optimizer = tf.keras.optimizers.Adam(self.critic_lr)\n",
        "        \n",
        "        self.actor_lr = self.actor_lr * self.lr_decay\n",
        "        self.actor_optimizer = tf.keras.optimizers.Adam(self.actor_lr)\n",
        "\n",
        "    def update_var(self):\n",
        "        self.var = np.max([0.1,self.var * self.var_decay])\n",
        "    \n",
        "    @tf.function\n",
        "    def update_critic(self, state_batch, action_batch, reward_batch, next_state_batch, done_batch):\n",
        "        target_actions = self.target_policy(next_state_batch) \n",
        "        target_1, target_2 = self.target_critic([next_state_batch, target_actions])\n",
        "        \n",
        "        target_vals =  tf.minimum(target_1, target_2)\n",
        "\n",
        "        y = tf.stop_gradient(reward_batch + (1-done_batch)* self.gamma*target_vals)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            \n",
        "            critic_value_1, critic_value_2 = self.critic([state_batch, action_batch])\n",
        "            \n",
        "            critic_loss = losses.huber_loss(y, critic_value_1) + losses.huber_loss(y, critic_value_2)\n",
        "\n",
        "        \n",
        "        critic_grad = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
        "        \n",
        "        self.critic_optimizer.apply_gradients(zip(critic_grad, self.critic.trainable_variables))\n",
        "\n",
        "\n",
        "       \n",
        "    @tf.function\n",
        "    def update_actor(self, state_batch, action_batch, reward_batch, next_state_batch, done_batch):\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(self.actor.trainable_variables)\n",
        "            actions = self.actor(state_batch)\n",
        "            critic_value_1,critic_value_2 = self.critic([state_batch, actions])\n",
        "            actor_loss = -tf.math.reduce_mean(critic_value_1)\n",
        "            \n",
        "        actor_grad = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
        "        \n",
        "        self.actor_optimizer.apply_gradients(\n",
        "            zip(actor_grad, self.actor.trainable_variables)\n",
        "        )\n",
        "\n",
        "   \n",
        "    \n",
        "        \n",
        "    def learn(self,episode):\n",
        "        # get sample\n",
        "\n",
        "        record_range = min(self.buffer.buffer_counter, self.buffer.buffer_capacity)\n",
        "\n",
        "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
        "\n",
        "        state_batch = tf.convert_to_tensor(self.buffer.state_buffer[batch_indices])\n",
        "        action_batch = tf.convert_to_tensor(self.buffer.action_buffer[batch_indices])\n",
        "        reward_batch = tf.convert_to_tensor(self.buffer.reward_buffer[batch_indices])\n",
        "        next_state_batch = tf.convert_to_tensor(self.buffer.next_state_buffer[batch_indices])\n",
        "\n",
        "        done_batch = tf.convert_to_tensor(self.buffer.done_buffer[batch_indices])\n",
        "        \n",
        "        self.update_critic(state_batch, action_batch, reward_batch, next_state_batch, done_batch)\n",
        "\n",
        "        if (episode % 2 == 0 and episode != 0):\n",
        "            self.update_actor(state_batch, action_batch, reward_batch, next_state_batch, done_batch)\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def update_target(self, target_weights, weights):\n",
        "        for (a,b) in zip(target_weights, weights):\n",
        "            a.assign(self.tau *b + (1-self.tau) *a)\n",
        "\n",
        "        \n",
        "    def get_critic_NN(self):\n",
        "        # input [state, action]\n",
        "        last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
        "\n",
        "        state_input = layers.Input(shape =(self.state_dim,))\n",
        "        action_input = layers.Input(shape =(self.action_dim,))\n",
        "\n",
        "        input = tf.concat([state_input, action_input],1)\n",
        "       \n",
        "        out_1 = layers.Dense(512, activation = 'relu')(input)\n",
        "        out_1 = layers.Dense(512, activation = 'relu')(out_1)\n",
        "        out_1 = layers.Dense(1, kernel_initializer= last_init)(out_1)\n",
        "\n",
        "        out_2 = layers.Dense(512, activation = 'relu')(input)\n",
        "        out_2 = layers.Dense(512, activation = 'relu')(out_2)\n",
        "        out_2 = layers.Dense(1, kernel_initializer= last_init)(out_2)\n",
        "\n",
        "\n",
        "\n",
        "        model = keras.Model(inputs = [state_input, action_input], outputs = [out_1,out_2])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_actor_NN(self):\n",
        "        \n",
        "        # Initialize weights between -3e-3 and 3-e3\n",
        "        last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
        "\n",
        "        inputs = layers.Input(shape=(self.state_dim,))\n",
        "       \n",
        "        out = layers.Dense(1024, activation=\"relu\")(inputs)\n",
        "        out = layers.BatchNormalization()(out)\n",
        "        out = layers.Dense(512, activation=\"relu\")(out)\n",
        "        outputs = layers.Dense(1, activation='tanh', kernel_initializer=last_init)(out)\n",
        "\n",
        "        # Our upper bound is 2.0 .\n",
        "        outputs = outputs * self.upper_action_bound\n",
        "        model = tf.keras.Model(inputs, outputs)\n",
        "        return model\n",
        "\n",
        "    def policy(self, state):\n",
        "        sampled_actions = tf.squeeze(self.actor(state))\n",
        "        \n",
        "        #noice = self.noice_Obj()\n",
        "      \n",
        "        sampled_actions = sampled_actions + np.random.normal(loc= 0, scale=self.var)\n",
        "\n",
        "        legal_action = np.clip(sampled_actions, self.lower_action_bound, self.upper_action_bound)\n",
        "\n",
        "        return [np.squeeze(legal_action)]\n",
        "        #return [np.squeeze(sampled_actions)]\n",
        "    \n",
        "    @tf.function\n",
        "    def target_policy(self, state):\n",
        "        sampled_actions = self.target_actor(state)\n",
        "        \n",
        "        #noice = self.noice_Obj()\n",
        "        noice = tf.random.normal(shape = sampled_actions.get_shape(), mean = 0.0, stddev = 0.2, dtype = tf.float32)\n",
        "        noice = tf.clip_by_value(noice, -0.5, 0.5)\n",
        "        sampled_actions = sampled_actions + noice\n",
        "        \n",
        "        legal_action = tf.clip_by_value(sampled_actions, clip_value_min = self.lower_action_bound, clip_value_max =self.upper_action_bound)\n",
        "\n",
        "        return legal_action"
      ],
      "metadata": {
        "id": "qLADrazCuHRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MC = Pendulum()\n",
        "\n",
        "ep_reward_list = []\n",
        "# To store average reward history of last few episodes\n",
        "avg_reward_list = []\n",
        "num_episode = 300\n",
        "decay = 0.9999\n",
        "for ep in range(num_episode):\n",
        "    \n",
        "    done = False\n",
        "    state = MC.env.reset()\n",
        "    #state = tf.expand_dims(tf.convert_to_tensor(state),0)\n",
        "    \n",
        "    state = np.reshape(state, [1,MC.state_dim])\n",
        "    episodic_reward = 0\n",
        "    t_counter = 0\n",
        "\n",
        "    #if (ep % 100 == 0 and ep != 0):\n",
        "        #MC.run_MC()\n",
        "    while(t_counter < 200):\n",
        "        \n",
        "        \n",
        "        action = MC.policy(state)\n",
        "        \n",
        "        new_state, reward, done, info = MC.env.step(action)\n",
        "        \n",
        "        #new_state = tf.expand_dims(tf.convert_to_tensor(new_state.reshape(MC.state_dim)),0)\n",
        "       \n",
        "        new_state = np.reshape(new_state, [1,MC.state_dim])\n",
        "        episodic_reward += reward\n",
        "        \n",
        "        MC.buffer.record((state,action,reward, new_state, done))\n",
        "       \n",
        "        if (ep >= 200):\n",
        "          MC.var = 0.1\n",
        "          MC.learn(t_counter)\n",
        "    \n",
        "          if (t_counter % 2 == 0 and t_counter != 0):\n",
        "                  MC.update_target(MC.target_critic.variables,MC.critic.variables)\n",
        "                  MC.update_target(MC.target_actor.variables, MC.actor.variables)\n",
        "\n",
        "        state = new_state\n",
        "\n",
        "        t_counter +=1\n",
        "        if (done):\n",
        "            break\n",
        "    ep_reward_list.append(episodic_reward)\n",
        "    # Mean of last 40 episodes\n",
        "    avg_reward = np.mean(ep_reward_list[-50:])\n",
        "    print(\"Episode * {} * Avg Reward is ==> {}, var ==> {}, actor_lr ==> {}\".format(ep, avg_reward, MC.var, MC.actor_lr))\n",
        "    avg_reward_list.append(avg_reward)\n",
        "# Plotting graph\n",
        "# Episodes versus Avg. Rewards\n",
        "plt.plot(avg_reward_list)\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Avg. Epsiodic Reward\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0ypT_D-luJVR",
        "outputId": "a2cdd5d4-dd2a-49c2-d505-41cb2f8a4ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode * 0 * Avg Reward is ==> -1024.1516625332363, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 1 * Avg Reward is ==> -1055.5780514928788, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 2 * Avg Reward is ==> -1284.9709175762828, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 3 * Avg Reward is ==> -1282.7175766111973, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 4 * Avg Reward is ==> -1280.527375624703, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 5 * Avg Reward is ==> -1210.7156456046596, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 6 * Avg Reward is ==> -1204.069603176484, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 7 * Avg Reward is ==> -1134.5814977177918, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 8 * Avg Reward is ==> -1198.886699779449, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 9 * Avg Reward is ==> -1260.227101782616, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 10 * Avg Reward is ==> -1260.8968618460576, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 11 * Avg Reward is ==> -1236.8376417943596, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 12 * Avg Reward is ==> -1199.1362075323461, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 13 * Avg Reward is ==> -1195.9386695981605, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 14 * Avg Reward is ==> -1185.3689338330767, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 15 * Avg Reward is ==> -1210.7831174435328, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 16 * Avg Reward is ==> -1195.7852933620263, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 17 * Avg Reward is ==> -1177.2924643425447, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 18 * Avg Reward is ==> -1218.0009368653843, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 19 * Avg Reward is ==> -1210.600501945565, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 20 * Avg Reward is ==> -1202.1253336218815, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 21 * Avg Reward is ==> -1223.0462028062223, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 22 * Avg Reward is ==> -1216.3795588707255, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 23 * Avg Reward is ==> -1228.0155953863823, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 24 * Avg Reward is ==> -1251.2368557412938, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 25 * Avg Reward is ==> -1248.7132336895293, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 26 * Avg Reward is ==> -1258.343578465473, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 27 * Avg Reward is ==> -1244.5355980413808, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 28 * Avg Reward is ==> -1227.4379211972393, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 29 * Avg Reward is ==> -1222.9226557701916, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 30 * Avg Reward is ==> -1240.3417375432984, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 31 * Avg Reward is ==> -1224.9347008009986, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 32 * Avg Reward is ==> -1231.5953947434427, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 33 * Avg Reward is ==> -1241.4228584429802, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 34 * Avg Reward is ==> -1236.0849645722517, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 35 * Avg Reward is ==> -1252.750217923001, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 36 * Avg Reward is ==> -1245.1062348621144, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 37 * Avg Reward is ==> -1239.977228683216, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 38 * Avg Reward is ==> -1243.5363386650813, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 39 * Avg Reward is ==> -1236.644706264777, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 40 * Avg Reward is ==> -1236.4678839954888, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 41 * Avg Reward is ==> -1246.3659872679204, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 42 * Avg Reward is ==> -1261.7431762748029, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 43 * Avg Reward is ==> -1264.9639483946476, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 44 * Avg Reward is ==> -1265.9961153039965, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 45 * Avg Reward is ==> -1256.259781985587, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 46 * Avg Reward is ==> -1252.2643681406876, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 47 * Avg Reward is ==> -1248.4811042302408, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 48 * Avg Reward is ==> -1246.7160560646766, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 49 * Avg Reward is ==> -1252.5801937135532, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 50 * Avg Reward is ==> -1264.351445890697, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 51 * Avg Reward is ==> -1262.034808621472, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 52 * Avg Reward is ==> -1242.2265069193154, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 53 * Avg Reward is ==> -1246.341912652547, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 54 * Avg Reward is ==> -1242.4061424882668, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 55 * Avg Reward is ==> -1256.3155404482304, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 56 * Avg Reward is ==> -1256.4069429789017, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 57 * Avg Reward is ==> -1278.7413988561088, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 58 * Avg Reward is ==> -1274.3632205048093, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 59 * Avg Reward is ==> -1263.3424536527284, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 60 * Avg Reward is ==> -1259.3989843539175, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 61 * Avg Reward is ==> -1259.3698463803617, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 62 * Avg Reward is ==> -1277.4777789851441, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 63 * Avg Reward is ==> -1285.9953227732724, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 64 * Avg Reward is ==> -1277.8961464719018, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 65 * Avg Reward is ==> -1265.4378738787532, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 66 * Avg Reward is ==> -1273.9474845457214, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 67 * Avg Reward is ==> -1284.9099819254143, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 68 * Avg Reward is ==> -1279.2232885422195, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 69 * Avg Reward is ==> -1278.9165528801946, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 70 * Avg Reward is ==> -1273.1286398115676, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 71 * Avg Reward is ==> -1276.2035848937924, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 72 * Avg Reward is ==> -1280.7549646367509, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 73 * Avg Reward is ==> -1283.3421139142927, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 74 * Avg Reward is ==> -1271.7498623551987, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 75 * Avg Reward is ==> -1271.4813467772938, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 76 * Avg Reward is ==> -1256.2417121391966, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 77 * Avg Reward is ==> -1263.4139606642802, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 78 * Avg Reward is ==> -1267.8508652150124, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 79 * Avg Reward is ==> -1277.7790066975447, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 80 * Avg Reward is ==> -1257.0133121579058, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 81 * Avg Reward is ==> -1276.8901243314785, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 82 * Avg Reward is ==> -1282.6249845015482, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 83 * Avg Reward is ==> -1281.0061711783644, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 84 * Avg Reward is ==> -1274.8607495682281, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 85 * Avg Reward is ==> -1264.4544512413954, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 86 * Avg Reward is ==> -1277.0036295772506, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 87 * Avg Reward is ==> -1290.6788565517445, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 88 * Avg Reward is ==> -1296.6432060055167, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 89 * Avg Reward is ==> -1301.955188410665, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 90 * Avg Reward is ==> -1296.7378975578945, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 91 * Avg Reward is ==> -1285.6067696501063, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 92 * Avg Reward is ==> -1260.018828833482, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 93 * Avg Reward is ==> -1257.6428711629158, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 94 * Avg Reward is ==> -1253.941726048788, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 95 * Avg Reward is ==> -1263.1887089956463, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 96 * Avg Reward is ==> -1274.949034410174, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 97 * Avg Reward is ==> -1277.0037827077501, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 98 * Avg Reward is ==> -1278.544674433369, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 99 * Avg Reward is ==> -1280.1371104950574, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 100 * Avg Reward is ==> -1279.0389500481836, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 101 * Avg Reward is ==> -1283.0169679847872, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 102 * Avg Reward is ==> -1306.516152612715, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 103 * Avg Reward is ==> -1302.5053829188164, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 104 * Avg Reward is ==> -1304.3459126077857, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 105 * Avg Reward is ==> -1299.1838051691493, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 106 * Avg Reward is ==> -1305.7776868063304, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 107 * Avg Reward is ==> -1293.786024475301, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 108 * Avg Reward is ==> -1295.4553001044362, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 109 * Avg Reward is ==> -1296.081652337013, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 110 * Avg Reward is ==> -1300.258605743746, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 111 * Avg Reward is ==> -1306.069835088465, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 112 * Avg Reward is ==> -1297.110948347609, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 113 * Avg Reward is ==> -1286.774967164304, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 114 * Avg Reward is ==> -1306.5306323193447, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 115 * Avg Reward is ==> -1308.5419055312113, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 116 * Avg Reward is ==> -1302.4394800895693, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 117 * Avg Reward is ==> -1303.2409651710516, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 118 * Avg Reward is ==> -1293.5118126365985, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 119 * Avg Reward is ==> -1295.0722503380869, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 120 * Avg Reward is ==> -1297.922545029402, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 121 * Avg Reward is ==> -1278.8539959705524, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 122 * Avg Reward is ==> -1276.2706816623497, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 123 * Avg Reward is ==> -1262.69141150475, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 124 * Avg Reward is ==> -1259.9690870889444, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 125 * Avg Reward is ==> -1262.725987232686, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 126 * Avg Reward is ==> -1282.1343491145205, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 127 * Avg Reward is ==> -1270.8860810336082, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 128 * Avg Reward is ==> -1288.52241501177, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 129 * Avg Reward is ==> -1276.1427193163724, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 130 * Avg Reward is ==> -1283.0335504627703, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 131 * Avg Reward is ==> -1280.9019465206193, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 132 * Avg Reward is ==> -1261.2268809600894, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 133 * Avg Reward is ==> -1261.770554170651, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 134 * Avg Reward is ==> -1271.4131893932408, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 135 * Avg Reward is ==> -1279.7260900830506, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 136 * Avg Reward is ==> -1267.1779244488807, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 137 * Avg Reward is ==> -1247.6745910262707, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 138 * Avg Reward is ==> -1248.0730752221048, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 139 * Avg Reward is ==> -1243.7425402405986, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 140 * Avg Reward is ==> -1238.8634385609166, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 141 * Avg Reward is ==> -1247.5115458023151, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 142 * Avg Reward is ==> -1251.99912601337, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 143 * Avg Reward is ==> -1249.7580320056277, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 144 * Avg Reward is ==> -1244.3395266757502, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 145 * Avg Reward is ==> -1241.540477892171, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 146 * Avg Reward is ==> -1223.3572060158176, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 147 * Avg Reward is ==> -1219.284457361055, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 148 * Avg Reward is ==> -1217.5771314837266, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 149 * Avg Reward is ==> -1197.8452645130567, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 150 * Avg Reward is ==> -1179.3275559787617, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 151 * Avg Reward is ==> -1175.2904906198598, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 152 * Avg Reward is ==> -1153.9842368292188, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 153 * Avg Reward is ==> -1143.2992479867944, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 154 * Avg Reward is ==> -1141.5637426457968, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 155 * Avg Reward is ==> -1138.7233266060307, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 156 * Avg Reward is ==> -1131.7989224780204, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 157 * Avg Reward is ==> -1122.5366691728063, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 158 * Avg Reward is ==> -1111.1490116019634, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 159 * Avg Reward is ==> -1109.5910211264486, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 160 * Avg Reward is ==> -1101.2749474884101, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 161 * Avg Reward is ==> -1102.907364316567, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 162 * Avg Reward is ==> -1109.4386112815998, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 163 * Avg Reward is ==> -1101.9269954016881, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 164 * Avg Reward is ==> -1092.608687930677, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 165 * Avg Reward is ==> -1089.4284292904856, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 166 * Avg Reward is ==> -1096.0765250178927, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 167 * Avg Reward is ==> -1103.8543485003124, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 168 * Avg Reward is ==> -1114.3972562189554, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 169 * Avg Reward is ==> -1111.130155627866, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 170 * Avg Reward is ==> -1106.0043024975143, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 171 * Avg Reward is ==> -1119.660721659528, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 172 * Avg Reward is ==> -1126.0833813429251, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 173 * Avg Reward is ==> -1131.279899796059, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 174 * Avg Reward is ==> -1126.7542719484084, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 175 * Avg Reward is ==> -1139.2527496660618, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 176 * Avg Reward is ==> -1119.8672513736822, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 177 * Avg Reward is ==> -1135.712142540815, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 178 * Avg Reward is ==> -1122.172752215043, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 179 * Avg Reward is ==> -1122.170135098925, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 180 * Avg Reward is ==> -1127.7707338998825, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 181 * Avg Reward is ==> -1112.3654146950994, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 182 * Avg Reward is ==> -1112.7679196055358, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 183 * Avg Reward is ==> -1102.2743420709435, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 184 * Avg Reward is ==> -1099.12213953718, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 185 * Avg Reward is ==> -1097.4403965779597, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 186 * Avg Reward is ==> -1100.4785080508748, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 187 * Avg Reward is ==> -1102.545476288625, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 188 * Avg Reward is ==> -1080.6252641447315, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 189 * Avg Reward is ==> -1086.3784795729862, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 190 * Avg Reward is ==> -1107.0965936234916, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 191 * Avg Reward is ==> -1102.4452199426157, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 192 * Avg Reward is ==> -1117.4011138728506, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 193 * Avg Reward is ==> -1115.394668792278, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 194 * Avg Reward is ==> -1135.9038141179988, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 195 * Avg Reward is ==> -1149.6219866426075, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 196 * Avg Reward is ==> -1149.6689506059251, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 197 * Avg Reward is ==> -1162.9956710293263, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 198 * Avg Reward is ==> -1166.4274464814348, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 199 * Avg Reward is ==> -1166.5679101622468, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 200 * Avg Reward is ==> -1179.651734716755, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 201 * Avg Reward is ==> -1194.4048218805747, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 202 * Avg Reward is ==> -1206.479252856301, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 203 * Avg Reward is ==> -1217.8922075109222, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 204 * Avg Reward is ==> -1234.269559315561, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 205 * Avg Reward is ==> -1236.2563277234979, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 206 * Avg Reward is ==> -1248.7687744561931, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 207 * Avg Reward is ==> -1266.5465655671737, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 208 * Avg Reward is ==> -1282.2422893091762, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 209 * Avg Reward is ==> -1286.9782538967258, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 210 * Avg Reward is ==> -1292.1557601504674, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 211 * Avg Reward is ==> -1294.7765662059196, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 212 * Avg Reward is ==> -1297.1025725232537, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 213 * Avg Reward is ==> -1309.0296416761332, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 214 * Avg Reward is ==> -1312.6048811081255, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 215 * Avg Reward is ==> -1326.552419308185, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 216 * Avg Reward is ==> -1324.4107657053862, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 217 * Avg Reward is ==> -1315.3354096430842, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 218 * Avg Reward is ==> -1308.9380590782853, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 219 * Avg Reward is ==> -1313.9353292723938, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 220 * Avg Reward is ==> -1325.8818300364549, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 221 * Avg Reward is ==> -1325.174927800458, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 222 * Avg Reward is ==> -1319.751923926376, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 223 * Avg Reward is ==> -1320.4551998276086, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 224 * Avg Reward is ==> -1327.554604920494, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 225 * Avg Reward is ==> -1318.9991843102564, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 226 * Avg Reward is ==> -1325.678026038676, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 227 * Avg Reward is ==> -1317.6256595362916, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 228 * Avg Reward is ==> -1324.1331442645126, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 229 * Avg Reward is ==> -1322.9437431655062, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 230 * Avg Reward is ==> -1311.4399871057674, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 231 * Avg Reward is ==> -1308.4219725249181, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 232 * Avg Reward is ==> -1308.4747847204023, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 233 * Avg Reward is ==> -1307.161329969018, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 234 * Avg Reward is ==> -1315.1646650158632, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 235 * Avg Reward is ==> -1297.0773449762196, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 236 * Avg Reward is ==> -1290.7315653134656, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 237 * Avg Reward is ==> -1294.4662079631248, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 238 * Avg Reward is ==> -1303.997804563367, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 239 * Avg Reward is ==> -1302.2837763315993, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 240 * Avg Reward is ==> -1293.315140031206, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 241 * Avg Reward is ==> -1297.2077483392368, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 242 * Avg Reward is ==> -1295.3000802099934, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 243 * Avg Reward is ==> -1292.1391189106344, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 244 * Avg Reward is ==> -1275.4630815882347, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 245 * Avg Reward is ==> -1265.9018928119353, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 246 * Avg Reward is ==> -1278.5684647711078, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 247 * Avg Reward is ==> -1269.9231889506905, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 248 * Avg Reward is ==> -1270.696004718389, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 249 * Avg Reward is ==> -1285.8686840793844, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 250 * Avg Reward is ==> -1289.0254686056164, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 251 * Avg Reward is ==> -1278.7781286138745, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 252 * Avg Reward is ==> -1277.3175730685316, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 253 * Avg Reward is ==> -1277.4539702421646, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 254 * Avg Reward is ==> -1267.4246383565223, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 255 * Avg Reward is ==> -1269.3759730816946, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 256 * Avg Reward is ==> -1260.3245742680667, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 257 * Avg Reward is ==> -1248.765134661624, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 258 * Avg Reward is ==> -1223.1107337061078, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 259 * Avg Reward is ==> -1218.5170771293638, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 260 * Avg Reward is ==> -1216.2999077505278, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 261 * Avg Reward is ==> -1192.1262221332431, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 262 * Avg Reward is ==> -1161.7680973783138, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 263 * Avg Reward is ==> -1136.1435195595495, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 264 * Avg Reward is ==> -1109.516022370548, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 265 * Avg Reward is ==> -1079.8503022760417, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 266 * Avg Reward is ==> -1053.8444229869167, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 267 * Avg Reward is ==> -1028.54288198968, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 268 * Avg Reward is ==> -1005.9352484927008, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 269 * Avg Reward is ==> -981.5751354604197, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 270 * Avg Reward is ==> -961.8173709373458, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 271 * Avg Reward is ==> -934.04288927038, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 272 * Avg Reward is ==> -912.0875868821935, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 273 * Avg Reward is ==> -892.0557295343903, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 274 * Avg Reward is ==> -872.4265173022884, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 275 * Avg Reward is ==> -844.7383101613538, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 276 * Avg Reward is ==> -825.5685690496773, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 277 * Avg Reward is ==> -806.743177218143, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 278 * Avg Reward is ==> -781.7178273123834, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 279 * Avg Reward is ==> -768.4124331601604, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 280 * Avg Reward is ==> -755.3905809690553, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 281 * Avg Reward is ==> -743.6357625936504, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 282 * Avg Reward is ==> -730.6612761461802, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 283 * Avg Reward is ==> -714.6865466257175, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 284 * Avg Reward is ==> -687.5707947546404, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 285 * Avg Reward is ==> -672.718596719655, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 286 * Avg Reward is ==> -661.6106893050925, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 287 * Avg Reward is ==> -640.6687281159506, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 288 * Avg Reward is ==> -621.6403272986852, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 289 * Avg Reward is ==> -599.7350701214924, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 290 * Avg Reward is ==> -576.0387331705442, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 291 * Avg Reward is ==> -548.7503692933667, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 292 * Avg Reward is ==> -518.7223409337864, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 293 * Avg Reward is ==> -503.0357790088581, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 294 * Avg Reward is ==> -487.01959228395907, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 295 * Avg Reward is ==> -462.5649370166263, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 296 * Avg Reward is ==> -437.3524362072196, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 297 * Avg Reward is ==> -418.1490796638175, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 298 * Avg Reward is ==> -395.6947359576878, var ==> 0.1, actor_lr ==> 0.0001\n",
            "Episode * 299 * Avg Reward is ==> -370.03323980811894, var ==> 0.1, actor_lr ==> 0.0001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}